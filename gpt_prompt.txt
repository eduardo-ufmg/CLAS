consider the following:

---------------------------

The Gabriel graph of a set of points consists of a graph whose set of vertices `V` and edges `E` must conform with the definition expressed by (1), where points `(pi , pj)` constitute an edge if, and only if, no other point is contained within the hypersphere of diameter `D(pi , pj)`, the distance between points `pi` and `pj`
`(pi , pj) ∈ E ↔ D²(pi , pj) ≤ [D²(pi , z) + D²(pj , z)] ∀z ∈ V, pi, pj != z` (1)
The graph `G = {V, E}` of a training data set `T = {(xi , yi)|i = 1, . . . , N}`, where `yi ∈ {+1, −1}` and `xi ∈ Rn` also has a set of support edges `SE`, which represents all the edges of `E` that have a pair of vertices `(xi , xj)` that belong to opposite classes.

The final classifier is obtained from a Hierarchical Expert Mixture (HME), in which each hyperplane associated with every `SE` will have a different weight according to the new input pattern `x` to be classified. The HME architecture is represented by a network, where the first layer corresponds to the local experts. Each expert is weighted according to
`cl(x) = exp( −( max( D(x, pk) ) )² / D(x, pl) ) ∀k = 1, ..., m` (4)
functions `h1(x), ..., hm(x)` represents the `m` specialist outputs, `pl = (xi + xj)/2` is the midpoint of the support edge formed by the vertices `xi` and `xj` and `D(x, pl)` is the distance between
sample `x` (to be labeled) and the midpoint `pl`. After calculating the weights by (4) a normalization is imposed, such that sum(cl(x)) = 1. Then, the final result of the classification is obtained by
`f(x) = sign(sum(hl(x) * cl(x)))`, where `hl = sign((x^T)wl − bl)`, where `wl` is defined as `(xl − xj)`, and the bias term `bl` is defined as `[(1/2)(xl + xj)]wl^T`

---------------------------

The Gabriel Graph computation and support edge extraction are already implemented. Its output is a csv file with the following format:

```
vertex0_id, |, feature0_0, feature0_1, ..., feature0_n, |, cluster0_id, |, adjacent_vertex0_0 - isSupportEdge, adjacent_vertex0_1 - isSupportEdge, ..., adjacent_vertex0_m - isSupportEdge
vertex1_id, |, feature1_0, feature1_1, ..., feature1_n, |, cluster1_id, |, adjacent_vertex1_0 - isSupportEdge, adjacent_vertex1_1 - isSupportEdge, ..., adjacent_vertex1_m - isSupportEdge
...
vertexk_id, |, featurek_0, featurek_1, ..., featurek_n, |, clusterk_id, |, adjacent_vertexk_0 - isSupportEdge, adjacent_vertexk_1 - isSupportEdge, ..., adjacent_vertexk_m - isSupportEdge
```

the custom types that hold that data are
```
class Vertex;
class Cluster;

typedef unsigned VertexID_t;

class Vertex
{
public:
  std::vector<double> features;
  std::vector< std::pair<VertexID_t, bool> > adjacents;
  double q;
  const Cluster* cluster;
  Vertex(std::vector<double> features, const Cluster* cluster) : features(features), cluster(cluster) {}
  Vertex() {}
};

typedef std::map<VertexID_t, std::shared_ptr<Vertex> > VertexMap;

class QualityMeasure
{
public:
  double sum_q;
  double magnitude;
};

class Cluster
{
public:
  VertexMap vertices;
  QualityMeasure Q;
  double threshold;
  double averageQuality;
  double stdDeviation;
};

using ClassType = std::variant<unsigned, std::string>;
typedef std::map<ClassType, Cluster> ClusterMap;
```

the function to read the data is
```
int readGraph(ClusterMap& clusters, const std::string& input_file_name_with_path)
```

it reads the csv file and populates the `clusters` map with the data.

write a C++ program that builds the hyperplanes and output them in a format you see fit. new data types and functions may be defined as needed
